{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Random_Forest.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MorganGautherot/Machine_Learning_Courses/blob/master/Random_Forest_%26_boosting.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hg3T8Kt4v4ej"
      },
      "source": [
        "# Random forest"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M46qWfm-_DUb"
      },
      "source": [
        "Now you have a better understanding of the decision tree. You will work with a model that can generate multiple trees and use them to obtain more accurate predictions for regression and classification."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sbGVpH-mARTR"
      },
      "source": [
        "### Preliminaries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m0aWG9rH-Pa9"
      },
      "source": [
        "# Load the library with the iris dataset\n",
        "from sklearn.datasets import load_iris\n",
        "\n",
        "# Load scikit's random forest classifier library\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# Load pandas\n",
        "import pandas as pd\n",
        "\n",
        "# Load numpy\n",
        "import numpy as np\n",
        "\n",
        "# Compute accurasy_score\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Set random seed\n",
        "np.random.seed(0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rkpst1AiAUz6"
      },
      "source": [
        "### Load data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1EG_qEfJAOXX"
      },
      "source": [
        "# Create an object called iris with the iris data\n",
        "iris = load_iris()\n",
        "\n",
        "# Create a dataframe with the four feature variables\n",
        "df = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
        "\n",
        "# View the top 5 rows\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nSIEC2SiAdez"
      },
      "source": [
        "# Add a new column with the species names, this is what we are going to try to predict\n",
        "df['species'] = pd.Categorical.from_codes(iris.target, iris.target_names)\n",
        "\n",
        "# View the top 5 rows\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wXFisfYtAbR3"
      },
      "source": [
        "### Train Test Split"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J_LOrn97wWXK"
      },
      "source": [
        "Use `train_test_split` to split your data into train and test dataset. \n",
        "\n",
        "If you need help feel free to check the [documentation](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cy-XT1cbAsog"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "### Your code start here ###\n",
        "\n",
        "# Use .iloc to select only X data\n",
        "X = \n",
        "\n",
        "# Use pd.factorize the target value into 0, 1, 2 classes.\n",
        "y =\n",
        "\n",
        "# split train test using skleanr test_size = 0.33, and random_state = 42\n",
        "X_train, X_test, y_train, y_test = \n",
        "\n",
        "### Your code end here ###"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iso1-J9pBNpw"
      },
      "source": [
        "# Show the number of observations for the test and training dataframes\n",
        "print('Number of observations in the training data:', len(X_train))\n",
        "print('Number of observations in the test data:',len(X_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZWeGvQVxCnsi"
      },
      "source": [
        "### Train model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r7uKtzARBWfO"
      },
      "source": [
        "### Your code start here ###\n",
        "\n",
        "# Instantiate model with 1000 decision trees and random state = 42\n",
        "rf = \n",
        "\n",
        "# Train the model on training data\n",
        "\n",
        "\n",
        "### Your code end here ###"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TK4YfEmeDK51"
      },
      "source": [
        "### Prediction on train and test set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L-0FF8T-DPvK"
      },
      "source": [
        "### Your code start here ###\n",
        "\n",
        "# Use the forest's predict method on the test data\n",
        "y_predict_train = \n",
        "y_predict_test = \n",
        "### Your code end here ###"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2i-NQdRBDUWc"
      },
      "source": [
        "### Compute accuracy for Training and Testing prediction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Uuq1CIQxUOW"
      },
      "source": [
        "Now it's time to compute `accuracy_Score`.\n",
        "\n",
        "Feel free to check the [doc](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html) if you need more informations "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H88Lb4ksCvTg"
      },
      "source": [
        "### Your code start here ###\n",
        "accuracy_train = \n",
        "accuracy_test = \n",
        "### Your code end here ###\n",
        "\n",
        "print(accuracy_train)\n",
        "print(accuracy_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_prhPZlGyptA"
      },
      "source": [
        "### Decision Boundary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CequVdaCx9Kf"
      },
      "source": [
        "# Parameters\n",
        "n_classes = 3\n",
        "plot_colors = \"ryb\"\n",
        "plot_step = 0.02\n",
        "\n",
        "# Load data\n",
        "iris = load_iris()\n",
        "\n",
        "for pairidx, pair in enumerate([[0, 1], [0, 2], [0, 3],\n",
        "                                [1, 2], [1, 3], [2, 3]]):\n",
        "    # We only take the two corresponding features\n",
        "    X = iris.data[:, pair]\n",
        "    y = iris.target\n",
        "\n",
        "    # Train\n",
        "    rf = RandomForestClassifier(n_estimators = 1000, random_state = 42).fit(X, y)\n",
        "\n",
        "    # Plot the decision boundary\n",
        "    plt.subplot(2, 3, pairidx + 1)\n",
        "\n",
        "    x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
        "    y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
        "    xx, yy = np.meshgrid(np.arange(x_min, x_max, plot_step),\n",
        "                         np.arange(y_min, y_max, plot_step))\n",
        "    plt.tight_layout(h_pad=0.5, w_pad=0.5, pad=2.5)\n",
        "\n",
        "    Z = rf.predict(np.c_[xx.ravel(), yy.ravel()])\n",
        "    Z = Z.reshape(xx.shape)\n",
        "    cs = plt.contourf(xx, yy, Z, cmap=plt.cm.RdYlBu)\n",
        "\n",
        "    plt.xlabel(iris.feature_names[pair[0]])\n",
        "    plt.ylabel(iris.feature_names[pair[1]])\n",
        "\n",
        "    # Plot the training points\n",
        "    for i, color in zip(range(n_classes), plot_colors):\n",
        "        idx = np.where(y == i)\n",
        "        plt.scatter(X[idx, 0], X[idx, 1], c=color, label=iris.target_names[i],\n",
        "                    cmap=plt.cm.RdYlBu, edgecolor='black', s=15)\n",
        "\n",
        "plt.suptitle(\"Decision surface of a random forest using paired features\")\n",
        "plt.legend(loc='lower right', borderpad=0, handletextpad=0)\n",
        "plt.axis(\"tight\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}