{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Penalized_logistic_regression.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"Mi63bIwZRqIX"},"source":["# Penalized logistic regression"]},{"cell_type":"markdown","metadata":{"id":"9bv_hmEwRzeB"},"source":["In this notebook, you will discover how to use penalized linear regression Lasso (L1), Ridge (L2) and Elasticnet (L1 + L2).\n","\n","These penalties integrated to the cost function will help you train less complex models to avoid overfitting."]},{"cell_type":"markdown","metadata":{"id":"6165F8g5SpVO"},"source":["# Packages importation"]},{"cell_type":"code","metadata":{"id":"OGTNRbpNRgE1"},"source":["# Importation of the data for our classification example\n","from sklearn.datasets import load_breast_cancer\n","\n","# Importation of the function to standardize the data\n","from sklearn.preprocessing import StandardScaler\n","\n","# Importation of the train_test_split function which split randomly our data \n","# into a train and test set\n","from sklearn.model_selection import train_test_split\n","\n","# Importation of the logistic regression algorithm\n","from sklearn.linear_model import LogisticRegression\n","\n","# Importation of the performance metrics\n","from sklearn.metrics import accuracy_score, precision_recall_curve, f1_score, roc_auc_score, roc_curve, confusion_matrix\n","\n","# Importation of the maplotlib package to create graphics\n","import matplotlib.pyplot as plt\n","\n","# Importation of numpy to use of vectors, matrices, tensors.\n","import numpy as np "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"pR2icedzSss9"},"source":["#Data Importation"]},{"cell_type":"code","metadata":{"id":"mR_YM7z6SuPf"},"source":["# Data frame for our classification\n","breast_cancer = load_breast_cancer()\n","X_classif = breast_cancer.data[:, ]\n","y_classif = breast_cancer.target"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"loBVRk-bSyOw"},"source":["Use the Sklearn function *train_test_split* to split your dataset into two random set.\n","\n","Use a random_state of 123 and use 10% of your dataset for the test set.\n","\n","Feel free to use the [doc](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html)."]},{"cell_type":"code","metadata":{"id":"TyeO9fCgS7tn"},"source":["# Use the function train_test_split to create your train and test set\n","X_train_classif, X_test_classif, y_train_classif, y_test_classif = None"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ZkMjV7hLWnQK"},"source":["# Step 1 : Data standardization\n","\n","For the use of a linear model it is essential to go through a step of normalization of the data.\n","\n","This step allows to make the model interpretable but also to facilitate the convergence of the model.\n","\n","Feel free to use the [doc](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html)."]},{"cell_type":"code","metadata":{"id":"bNhI9DkXWq_s"},"source":["# Initialize the StandardScaler function\n","scaler = None\n","\n","# Fit the StandardScaler on the trainig set\n","None\n","\n","# Standardization of the training set\n","X_train_classif_norm = None\n","\n","# Standardization of the validation set\n","X_test_classif_norm = None"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Q-vUcTC5WtHS"},"source":["print('Mean of the training set : '+str(X_train_classif_norm.mean(axis=0)))\n","print('Standard deviation of the training set : '+str(X_train_classif_norm.std(axis=0)))\n","\n","print('Mean of the testing set : '+str(X_test_classif_norm.mean(axis=0)))\n","print('Standard deviation of the testing set : '+str(X_test_classif_norm.std(axis=0)))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"kMM_d7MVXAop"},"source":["Answers expected :\n","\n","Mean of the training set : [-5.13911830e-16 -3.05745013e-16  8.53483950e-16  1.10003152e-15\n","  1.54650598e-15  7.12049777e-16 -3.42607887e-17  1.31622144e-16\n"," -4.95350289e-15  7.66292411e-15  1.53913340e-15  1.52915874e-15\n","  2.89265140e-16 -2.73435788e-16  1.46914815e-15  1.42854478e-15\n","  1.64798730e-17 -4.59701721e-16 -1.22119112e-15 -1.23165367e-16\n","  7.01695646e-16  3.83720833e-15 -9.50628465e-16  2.82326246e-16\n","  4.31078784e-15 -3.93619599e-16  2.29850861e-16  1.19966970e-16\n"," -4.12918397e-15  3.31635761e-15]\n","\n","\n","Standard deviation of the training set : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n"," 1. 1. 1. 1. 1. 1.]\n","\n","\n","Mean of the testing set : [ 0.05124296 -0.18874973  0.03751984  0.03937833 -0.08482864 -0.18283252\n"," -0.07809671 -0.05164212 -0.19793932 -0.29018854  0.16691644 -0.05227523\n","  0.14396937  0.1740289   0.00614669 -0.25922462 -0.16597387 -0.12024983\n"," -0.11072004 -0.29499964  0.04435633 -0.07442118  0.0294974   0.01545994\n"," -0.02918828 -0.1089334  -0.05586924 -0.0412101  -0.06118219 -0.18438358]\n","\n"," \n","Standard deviation of the testing set : [0.91480598 0.66909629 0.90978263 1.03432425 0.99367801 0.87525274\n"," 0.90633893 0.90440753 0.71909467 0.84083134 1.57807166 0.87352948\n"," 1.60204167 1.78225409 1.01625717 0.75721494 0.65688383 0.93341027\n"," 0.99874551 0.56807441 0.84475039 0.80330342 0.84141439 0.89898207\n"," 0.95859295 1.1139185  1.010088   0.95613581 1.03214445 1.24999311]"]},{"cell_type":"markdown","metadata":{"id":"GO0eskyBXDHn"},"source":["# Step 2 : Model initialization"]},{"cell_type":"markdown","metadata":{"id":"SdmP_FNcXEuJ"},"source":["In the case of regression, there is no choice of hyperparameter.\n","\n","It is therefore sufficient to just initialize the function.\n","\n","Feel free to use the [doc](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html)."]},{"cell_type":"code","metadata":{"id":"LnHO1Y6-W_1B"},"source":["reg = None"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"dYFJhEGdXNKw"},"source":["In the case of lasso regression, you have to choose a value for alpha.\n","\n","Alpha will control the regularization of the model.\n","\n","$ J(w) =  \\frac{1}{2m}[\\frac{1}{C}\\sum^m_{i=1}(\\hat{y}^{(i)}-y^{(i)})^2+\\sum^n_{j=1}|w_j|]$ \n","\n","For logistic regression in Sklearn you will use the same function for all penalization and just precise the type of penalty you want with the parameter *penalty*.\n","\n","For this example initialize the regression with an alpha of 0.8, solver='saga' and a random_state of 123.\n","\n","Feel free to use the [doc](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html)."]},{"cell_type":"code","metadata":{"id":"Gd9OqjhcXO2P"},"source":["lasso = None"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"DdAWl4biXQWE"},"source":["In the case of ridge regression, you have to choose a value for alpha.\n","\n","Alpha will control the regularization of the model.\n","\n","$ J(w) =  \\frac{1}{2m}[\\frac{1}{C}\\sum^m_{i=1}(\\hat{y}^{(i)}-y^{(i)})^2+\\sum^n_{j=1}w_j^2]$ \n","\n","For logistic regression in Sklearn you will use the same function for all penalization and just precise the type of penalty you want with the parameter *penalty*.\n","\n","For this example initialize the regression with an alpha of 0.8 and a random_state of 123.\n","\n","Feel free to use the [doc](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html)."]},{"cell_type":"code","metadata":{"id":"GjL9ifDFXQ6e"},"source":["ridge = None"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"y50zJR2zXRcd"},"source":["In the case of elasticnet regression, you have to choose a value for alpha and ratio.\n","\n","Alpha will control the regularization of the model.\n","\n","ratio is the mixing parameter beween lasso (ratio=0) and ridge (ratio=1)\n","\n","$ J(w) =  \\frac{1}{2m}[\\frac{1}{C}\\sum^m_{i=1}(\\hat{y}^{(i)}-y^{(i)})^2+\\frac{1-ratio}{2}\\sum^n_{j=1}w_j^2 + ratio\\sum^n_{j=1}|w_j|]$ \n","\n","For logistic regression in Sklearn you will use the same function for all penalization and just precise the type of penalty you want with the parameter *penalty*.\n","\n","For this example initialize the regression with an alpha of 0.8, a ratio of 0.5, solver equal saga and a random_state of 123.\n","\n","Feel free to use the [doc](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html)."]},{"cell_type":"code","metadata":{"id":"1UBh-J23XRr_"},"source":["elasticnet = None"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Aa_W0KgA8ckm"},"source":["# Step 3 : Model training"]},{"cell_type":"markdown","metadata":{"id":"-A6JKhXgmPJx"},"source":["You must train the four models."]},{"cell_type":"code","metadata":{"id":"jeabnIY1mYRx"},"source":["# Classic linear regression\n","None"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XwaJMN79mZRc"},"source":["# Lasso regression\n","None"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"KadiiuyRmZgT"},"source":["# Ridge regression\n","None"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-klrFThemZxG"},"source":["# ElasticNet regression\n","None"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"NnfEUR7W8hoj"},"source":["# Step 4 : Model validation"]},{"cell_type":"markdown","metadata":{"id":"bEtaZWX7mrrY"},"source":["Your model is now trained, use it to predict the probability for your training and testing set for the four models."]},{"cell_type":"code","metadata":{"id":"SiojbymLmyaa"},"source":["# Classic linear regression one hot prediction\n","x_train_reg_prediction = None\n","\n","x_test_reg_prediction = None\n","\n","# Classic linear regression probability \n","x_train_reg_prediction_proba = None\n","\n","x_test_reg_prediction_proba = None"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"MOkNCCvjmyTN"},"source":["# Lasso regression\n","x_train_lasso_prediction = None\n","\n","x_test_lasso_prediction = None\n","\n","# Classic linear regression probability \n","x_train_lasso_prediction_proba = None\n","\n","x_test_lasso_prediction_proba = None"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WmBIISUImyMw"},"source":["# Ridge regression\n","x_train_ridge_prediction = None\n","\n","x_test_ridge_prediction = None\n","\n","# Classic linear regression probability \n","x_train_ridge_prediction_proba = None\n","\n","x_test_ridge_prediction_proba = None"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"EwNW7i3LmyFy"},"source":["# ElasticNet regression\n","x_train_elasticnet_prediction = None\n","\n","x_test_elasticnet_prediction = None\n","\n","# Classic linear regression probability \n","x_train_elasticnet_prediction_proba = None\n","\n","x_test_elasticnet_prediction_proba = None"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"nhMntqu3nLXg"},"source":["Compute the AUC for each model"]},{"cell_type":"code","metadata":{"id":"3laSbjqQnRuU"},"source":["# Classic linear regression\n","auc_train = None\n","\n","auc_test = None\n","\n","print('AUC for the training set : '+str(auc_train))\n","\n","print('AUC for the testing set : '+str(auc_test))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8XUQ18VonRoP"},"source":["# Lasso regression\n","auc_train = None\n","\n","auc_test = None\n","\n","print('AUC for the training set : '+str(auc_train))\n","\n","print('AUC for the testing set : '+str(auc_test))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"tMNYDhdLnRiE"},"source":["# Ridge regression\n","auc_train = None\n","\n","auc_test = None\n","\n","print('AUC for the training set : '+str(auc_train))\n","\n","print('AUC for the testing set : '+str(auc_test))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"KR50bGBBnRcW"},"source":["# ElasticNet regression\n","auc_train = None\n","\n","auc_test = None\n","\n","print('AUC for the training set : '+str(auc_train))\n","\n","print('AUC for the testing set : '+str(auc_test))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-JZ4LWuO8p0c"},"source":["# Step 5 : Impact of the regularization term on the coefficient"]},{"cell_type":"markdown","metadata":{"id":"z3t6KupmuXAJ"},"source":["Impact of the regularization term for the Lasso regression."]},{"cell_type":"code","metadata":{"id":"jD8C0WgXpSFQ"},"source":["for alpha_values in [0.01, 0.1, 0.2, 0.5, 1] :\n","  # Initiate your model with alpha equal to alpha_values and random_state of 123\n","  lasso = None\n","\n","  # Train your model using X_train_reg_norm and y_train_reg\n","  None\n","  print('Alpha = '+str(alpha_values))\n","  print(lasso.coef_)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4xBwTZIbuzPB"},"source":["Impact of the regularization term for the Ridge regression."]},{"cell_type":"code","metadata":{"id":"C-QcyLRQu34C"},"source":["for alpha_values in [0.01, 0.1, 1, 10] :\n","  # Initiate your model with alpha equal to alpha_values and random_state of 123\n","  ridge = None\n","\n","  # Train your model using X_train_reg_norm and y_train_reg\n","  None\n","  print('Alpha = '+str(alpha_values))\n","  print(ridge.coef_)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"FKas_381vTjr"},"source":["Impact of the regularization term and the l1_ratio for the elasticnet regression."]},{"cell_type":"code","metadata":{"id":"cjwrGLXhuH8B"},"source":["for alpha_values, ratio_values in zip([0.01, 0.01, 0.1, 0.5, 1, 1], [0, 1, 0.5, 0.5, 1, 0]) :\n","  # Initiate your model with alpha equal to alpha_values, l1_ratio equal to ratio_values and random_state of 123\n","  elasticnet = None\n","\n","  # Train your model using X_train_reg_norm and y_train_reg\n","  None\n","  print('Alpha = '+str(alpha_values))\n","  print('ratio_values = '+str(ratio_values))\n","  print(elasticnet.coef_)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"eG8phJVmwXEx"},"source":[""],"execution_count":null,"outputs":[]}]}